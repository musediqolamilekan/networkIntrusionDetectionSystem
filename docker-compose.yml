version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - '2181:2181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      start_period: 10s
      retries: 20
      interval: 10s
    networks:
      - NDIS-net

  broker:
    image: confluentinc/cp-kafka:7.4.0
    hostname: broker
    container_name: broker
    ports:
      - '29092:29092'
      - '9092:9092'
      - '9101:9101'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - NDIS-net

  connect:
    image: confluentinc/cp-kafka-connect:7.4.0
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: 'compose-connect-group'
      CONNECT_CONFIG_STORAGE_TOPIC: 'docker-connect-configs'
      CONNECT_OFFSET_STORAGE_TOPIC: 'docker-connect-offsets'
      CONNECT_STATUS_STORAGE_TOPIC: 'docker-connect-status'
      CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_REST_ADVERTISED_HOST_NAME: 'connect'
      CONNECT_LOG4J_LOGGERS: 'org.apache.kafka.connect.runtime.rest=WARN,org.reflections=WARN'
    depends_on:
      - broker
    networks:
      - NDIS-net

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.4.0
    hostname: control-center
    container_name: control-center
    depends_on:
      broker:
        condition: service_healthy
    ports:
      - '9021:9021'
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: broker:29092
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONFLUENT_METRICS_ENABLE: 'false'
      PORT: 9021
    networks:
      - NDIS-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9021/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  debezium:
    image: debezium/connect:latest
    container_name: debezium
    hostname: debezium
    depends_on:
      postgres:
        condition: service_healthy
      broker:
        condition: service_healthy
    ports:
      - '8093:8083'
    environment:
      BOOTSTRAP_SERVERS: broker:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: debezium
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      STATUS_STORAGE_TOPIC: connect_statuses
      OFFSET_STORAGE_TOPIC: connect_offsets
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      ENABLE_DEBEZIUM_SCRIPTING: 'true'
    healthcheck:
      test: ['CMD', 'curl', '--silent', '--fail', '-X', 'GET', 'http://localhost:8083/connectors']
      start_period: 10s
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - NDIS-net

  debezium-ui:
    image: debezium/debezium-ui:latest
    container_name: debezium-ui
    hostname: debezium-ui
    depends_on:
      debezium:
        condition: service_healthy
    ports:
      - '8080:8080'
    environment:
      KAFKA_CONNECT_URIS: http://debezium:8083
    networks:
      - NDIS-net

  postgres:
    image: postgres:latest
    container_name: postgres
    hostname: postgres
    ports:
      - '5432:5432'
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: network_db
    command: ['postgres', '-c', 'wal_level=logical']
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U postgres']
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - NDIS-net

  # Packet Capture and Preprocessing
  packet-capture:
    build:
      context: .
      dockerfile: ./images/Dockerfile.packet-capture
    container_name: packet-capture
    hostname: packet-capture
    environment:
      - KAFKA_BROKER=broker:29092
    networks:
      - NDIS-net
    cap_add:
      - NET_ADMIN

  # Machine Learning for Anomaly Detection
  ml-anomaly-detection:
    build:
      context: .
      dockerfile: ./images/Dockerfile.ml-anomaly-detection
    container_name: ml-anomaly-detection
    hostname: ml-anomaly-detection
    depends_on:
      broker:
        condition: service_healthy
    environment:
      - KAFKA_BROKER=broker:29092
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=network_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    networks:
      - NDIS-net

  # Alerting and Monitoring
  alerting:
    build:
      context: .
      dockerfile: ./images/Dockerfile.alert
    container_name: alerting
    hostname: alerting
    depends_on:
      broker:
        condition: service_healthy
    environment:
      - KAFKA_BROKER=broker:29092
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=network_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    networks:
      - NDIS-net

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - NDIS-net

  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.0
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - NDIS-net

  logstash:
    image: docker.elastic.co/logstash/logstash:7.10.0
    container_name: logstash
    volumes:
      - ./config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch
      - broker
    networks:
      - NDIS-net

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.10.0
    container_name: filebeat
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/log:/var/log:ro
    depends_on:
      - logstash
    networks:
      - NDIS-net

volumes:
  esdata:
    driver: local

networks:
  NDIS-net:
    name: NDIS-net
    driver: bridge
